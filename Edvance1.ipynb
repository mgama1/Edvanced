{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3a3e7e-0f95-4b4f-9504-c9b8782efbec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6b3a504e-668e-4c3f-9019-eda143f4bdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7073b17c-ac69-44ae-9965-7ffd48db8f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIDCornerMap(gray):\n",
    "        \n",
    "    aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_100)\n",
    "    parameters = cv2.aruco.DetectorParameters()\n",
    "    \n",
    "    detector = cv2.aruco.ArucoDetector(aruco_dict, parameters)\n",
    "    corners, ids, _ = detector.detectMarkers(gray)\n",
    "    if ids is None or len(ids) < 4:\n",
    "        raise ValueError(\"Not all 4 ArUco markers were detected.\")\n",
    "    \n",
    "    # Create a dictionary to map ID to its corner\n",
    "    id_corner_map = {}\n",
    "    for id, corner in zip(ids, corners):\n",
    "        id_corner_map[id[0]] = corner\n",
    "    \n",
    "    if (48 in id_corner_map):\n",
    "        nc=5\n",
    "    elif (49 in id_corner_map):\n",
    "        nc=4\n",
    "    return id_corner_map,nc\n",
    "\n",
    "def get_center(corner):\n",
    "    return corner[0].mean(axis=0)\n",
    "def get_centeroid(array):\n",
    "    return np.array(array).mean(axis=0)\n",
    "def getROI(id_corner_map):\n",
    "    '''returns the orderded center of the four corners locations\n",
    "    and metadata:number of choices per questions\n",
    "    '''\n",
    "    if (48 in id_corner_map):\n",
    "        ordered_ids = [30, 10, 48, 34]  # TL, TR, BR, BL\n",
    "    elif (49 in id_corner_map):\n",
    "        ordered_ids = [30, 10, 49, 34]  # TL, TR, BR, BL\n",
    "        \n",
    "    ordered_pts = [get_center(id_corner_map[id]) for id in ordered_ids]\n",
    "    \n",
    "    roi= np.array(ordered_pts, dtype='float32')\n",
    "    return roi\n",
    "\n",
    "def getWarpedImage(src_pts,image):\n",
    "    width, height = int(image.shape[0]*.764),image.shape[0]\n",
    "    dst_pts = np.array([\n",
    "        [0, 0],\n",
    "        [width - 1, 0],\n",
    "        [width - 1, height - 1],\n",
    "        [0, height - 1]\n",
    "    ], dtype='float32')\n",
    "    M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
    "    warped = cv2.warpPerspective(image, M, (width, height))\n",
    "    return warped\n",
    "\n",
    "def getLargestContour(image,drawContour=False):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "    edged = cv2.Canny(gray, 30, 200) \n",
    "    \n",
    "\n",
    "    contours, hierarchy = cv2.findContours(edged, \n",
    "    \tcv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) \n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    \n",
    "    #draw for debugging\n",
    "    if drawContour:\n",
    "        cv2.drawContours(image, largest_contour, -1, (0, 255, 0), 3) \n",
    "        cv2.imshow('largest contour', image) \n",
    "        cv2.waitKey(0) \n",
    "        cv2.destroyAllWindows() \n",
    "    return largest_contour\n",
    "\n",
    "def getBubbleContours(binary_image,drawContours=False):\n",
    "   \n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, \n",
    "                                   cv2.CHAIN_APPROX_NONE)\n",
    "    bubble_contours = []\n",
    "    for c in contours:\n",
    "        area = cv2.contourArea(c)\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        aspect_ratio = w / float(h)\n",
    "        \n",
    "        if area > 50 and 0.9 < aspect_ratio < 1.1:\n",
    "            bubble_contours.append(c)\n",
    "    \n",
    "    #sorting\n",
    "    bubble_contours.sort(key=lambda b:get_centeroid(b)[0][1])\n",
    "    \n",
    "    # For sorting 15 elements at a time\n",
    "    for i in range(10):  # Assuming you have 10 groups of 15 elements\n",
    "        # Calculate the start and end indices for the current group\n",
    "        start_idx = i * 15\n",
    "        end_idx = (i + 1) * 15  # This gives you exactly 15 elements\n",
    "        \n",
    "        # Sort this slice and assign it back using sorted() which returns a new sorted list\n",
    "        bubble_contours[start_idx:end_idx] = sorted(bubble_contours[start_idx:end_idx],key=lambda b: get_centeroid(b)[0][0])\n",
    "    \n",
    "    if drawContours:\n",
    "        output = cropped.copy()\n",
    "        cv2.drawContours(output, bubble_contours, -1, (0, 255, 0), 2)\n",
    "        output_resized = cv2.resize(output, (800, int(output.shape[0] * 800 / output.shape[1])))\n",
    "        cv2.imshow('Detected Bubbles', output_resized)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    return bubble_contours\n",
    "\n",
    "def getFilledBubblesMatrix(bubble_contours,binary_image):\n",
    "    extracted_matrix=[]\n",
    "    for c in bubble_contours:\n",
    "        # Step 1: Create a black mask\n",
    "        mask = np.zeros(binary_image.shape, dtype=\"uint8\")\n",
    "    \n",
    "        # Step 2: Draw the bubble contour filled with white on the mask\n",
    "        cv2.drawContours(mask, [c], -1, 255, -1)\n",
    "    \n",
    "        # Step 3: Apply the mask to binary_image image\n",
    "        masked_bubble = cv2.bitwise_and(binary_image, binary_image, mask=mask)\n",
    "    \n",
    "        # Step 4: Calculate number of white pixels\n",
    "        total = cv2.countNonZero(mask)\n",
    "        filled = cv2.countNonZero(masked_bubble)\n",
    "    \n",
    "        fill_ratio = filled / total\n",
    "        #print(fill_ratio)\n",
    "        if fill_ratio > 0.5:  # You can tweak 0.5 based on real data\n",
    "            extracted_matrix.append(1)\n",
    "        else:\n",
    "            extracted_matrix.append(0)\n",
    "    \n",
    "    #np.array(extracted_matrix).reshape(10,15)\n",
    "    return np.array(extracted_matrix).reshape(-1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2791c318-eac6-42fe-b394-1fc5a459cbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BubbleSheetGrader:\n",
    "    def __init__(self,image_path):\n",
    "        self.image_path=image_path\n",
    "        self.nc=None\n",
    "        self.image=None\n",
    "        self.gray=None\n",
    "        self.warped=None\n",
    "        self.cropped=None\n",
    "        self.thresh=None\n",
    "        self.bubble_contours=None\n",
    "        self.result=None\n",
    "    def load_image(self):\n",
    "        self.image = cv2.imread(self.image_path)\n",
    "        self.gray = cv2.cvtColor(self.image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    def warp_paper(self):\n",
    "        id_corner_map,self.nc=getIDCornerMap(self.gray)\n",
    "        self.warped=getWarpedImage(src_pts = getROI(id_corner_map),image=self.image)\n",
    "    def preprocess_cropped(self):\n",
    "        x, y, w, h = cv2.boundingRect(getLargestContour(warped))\n",
    "        self.cropped = self.warped[y+10:y+h-10, x+10:x+w-10]\n",
    "        \n",
    "        cropped_gray = cv2.cvtColor(self.cropped, cv2.COLOR_BGR2GRAY)\n",
    "        blurred = cv2.GaussianBlur(cropped_gray, (3, 3), 0)\n",
    "        #return binary image based on adaptive thresholding\n",
    "        self.thresh = cv2.adaptiveThreshold(blurred, 255, \n",
    "                                       cv2.ADAPTIVE_THRESH_MEAN_C, \n",
    "                                       cv2.THRESH_BINARY_INV, 49, 20)\n",
    "    def extract_bubble_contours(self):\n",
    "        self.bubble_contours=getBubbleContours(self.thresh,False)\n",
    "\n",
    "    def extractAndEvaluateAnswerMatrix():\n",
    "        answer_matrix=getFilledBubblesMatrix(bubble_contours,thresh)\n",
    "        self.result =np.all(sam==mam,axis=1).sum()\n",
    "    def run_pipeline(self):\n",
    "        self.load_image()\n",
    "        self.warp_paper()\n",
    "        self.preprocess_cropped()\n",
    "        self.extract_bubble_contours()\n",
    "        self.extractAndEvaluateAnswerMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b3f2c6-44e6-4f67-871c-98e623955a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0eeaccdf-5866-4788-ae31-bcd7add73cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../Downloads/studentanswer.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f34dcef7-0345-449f-92bd-9fac73a345c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_corner_map,nc=getIDCornerMap(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b30c7376-2257-429e-a9d7-4a0c46dee443",
   "metadata": {},
   "outputs": [],
   "source": [
    "warped=getWarpedImage(src_pts = getROI(id_corner_map),image=image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28726be3-74dd-4a06-bc5d-9fc39c255710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7676993d-6c73-4bec-a9a8-e98fb3f90fb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "aa9b6921-fd20-4882-abb2-3395ff30b05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, w, h = cv2.boundingRect(getLargestContour(warped))\n",
    "cropped = warped[y+10:y+h-10, x+10:x+w-10]\n",
    "\n",
    "cropped_gray = cv2.cvtColor(cropped, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(cropped_gray, (3, 3), 0)\n",
    "#return binary image based on adaptive thresholding\n",
    "thresh = cv2.adaptiveThreshold(blurred, 255, \n",
    "                               cv2.ADAPTIVE_THRESH_MEAN_C, \n",
    "                               cv2.THRESH_BINARY_INV, 49, 20)\n",
    "\n",
    "bubble_contours=getBubbleContours(thresh,True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd715d3-67b8-4964-b15b-6ff2827f999b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "32d9e0c1-4dea-44be-a79a-a0326431d48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sam=getFilledBubblesMatrix(bubble_contours,thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a5fd53-b497-4495-8029-72b858e86b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f8baf058-199a-4f55-a805-66d337fa6bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sam==mam\n",
    "np.all(sam==mam,axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f78e60-f1b4-47c7-a5f1-0983ad5d2a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8eb19c6-640e-444d-9463-6e1eae052ce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b915c4c7-5b18-43eb-abab-a9ac3bb278ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed436d4-d4e2-4451-922b-95cf6776314b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e072b8-0a1f-4b6f-8b81-037fdb64fb1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8453b4-0925-4174-b25d-d4552b6cf597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a10b65-11f9-437f-b5e8-a5400639e3fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cef6f3-d11b-4570-a613-5ee3e60a24a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb52a6d2-ce54-40b0-b82a-f815da9a1d06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22cefdf-ccb3-4780-bdb7-fde6328f7315",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
