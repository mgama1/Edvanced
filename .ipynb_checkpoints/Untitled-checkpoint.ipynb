{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49a7ab79-d990-4cf7-9b91-1e1a438d1721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def getIDCornerMap(gray):\n",
    "        \n",
    "    aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_100)\n",
    "    parameters = cv2.aruco.DetectorParameters()\n",
    "    \n",
    "    detector = cv2.aruco.ArucoDetector(aruco_dict, parameters)\n",
    "    corners, ids, _ = detector.detectMarkers(gray)\n",
    "    if ids is None or len(ids) < 4:\n",
    "        raise ValueError(\"Not all 4 ArUco markers were detected.\")\n",
    "    \n",
    "    # Create a dictionary to map ID to its corner\n",
    "    id_corner_map = {}\n",
    "    for id, corner in zip(ids, corners):\n",
    "        id_corner_map[id[0]] = corner\n",
    "    \n",
    "    if (48 in id_corner_map):\n",
    "        nc=5\n",
    "    elif (49 in id_corner_map):\n",
    "        nc=4\n",
    "    return id_corner_map,nc\n",
    "\n",
    "def get_center(corner):\n",
    "    return corner[0].mean(axis=0)\n",
    "def get_centeroid(array):\n",
    "    return np.array(array).mean(axis=0)\n",
    "def getROI(id_corner_map):\n",
    "    '''returns the orderded center of the four corners locations\n",
    "    and metadata:number of choices per questions\n",
    "    '''\n",
    "    if (48 in id_corner_map):\n",
    "        ordered_ids = [30, 10, 48, 34]  # TL, TR, BR, BL\n",
    "    elif (49 in id_corner_map):\n",
    "        ordered_ids = [30, 10, 49, 34]  # TL, TR, BR, BL\n",
    "        \n",
    "    ordered_pts = [get_center(id_corner_map[id]) for id in ordered_ids]\n",
    "    \n",
    "    roi= np.array(ordered_pts, dtype='float32')\n",
    "    return roi\n",
    "\n",
    "def getWarpedImage(src_pts,image):\n",
    "    width, height = int(image.shape[0]*.764),image.shape[0]\n",
    "    dst_pts = np.array([\n",
    "        [0, 0],\n",
    "        [width - 1, 0],\n",
    "        [width - 1, height - 1],\n",
    "        [0, height - 1]\n",
    "    ], dtype='float32')\n",
    "    M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
    "    warped = cv2.warpPerspective(image, M, (width, height))\n",
    "    return warped\n",
    "\n",
    "def getLargestContour(image,drawContour=False):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "    edged = cv2.Canny(gray, 30, 200) \n",
    "    \n",
    "\n",
    "    contours, hierarchy = cv2.findContours(edged, \n",
    "    \tcv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) \n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    \n",
    "    #draw for debugging\n",
    "    if drawContour:\n",
    "        cv2.drawContours(image, largest_contour, -1, (0, 255, 0), 3) \n",
    "        cv2.imshow('largest contour', image) \n",
    "        cv2.waitKey(0) \n",
    "        cv2.destroyAllWindows() \n",
    "    return largest_contour\n",
    "\n",
    "def getBubbleContours(binary_image,drawContours=False):\n",
    "   \n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, \n",
    "                                   cv2.CHAIN_APPROX_NONE)\n",
    "    bubble_contours = []\n",
    "    for c in contours:\n",
    "        area = cv2.contourArea(c)\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        aspect_ratio = w / float(h)\n",
    "        \n",
    "        if area > 50 and 0.9 < aspect_ratio < 1.1:\n",
    "            bubble_contours.append(c)\n",
    "    \n",
    "    #sorting\n",
    "    bubble_contours.sort(key=lambda b:get_centeroid(b)[0][1])\n",
    "    \n",
    "    # For sorting 15 elements at a time\n",
    "    for i in range(10):  # Assuming you have 10 groups of 15 elements\n",
    "        # Calculate the start and end indices for the current group\n",
    "        start_idx = i * 15\n",
    "        end_idx = (i + 1) * 15  # This gives you exactly 15 elements\n",
    "        \n",
    "        # Sort this slice and assign it back using sorted() which returns a new sorted list\n",
    "        bubble_contours[start_idx:end_idx] = sorted(bubble_contours[start_idx:end_idx],key=lambda b: get_centeroid(b)[0][0])\n",
    "    \n",
    "    if drawContours:\n",
    "        output = cropped.copy()\n",
    "        cv2.drawContours(output, bubble_contours, -1, (0, 255, 0), 2)\n",
    "        output_resized = cv2.resize(output, (800, int(output.shape[0] * 800 / output.shape[1])))\n",
    "        cv2.imshow('Detected Bubbles', output_resized)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    return bubble_contours\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de26c09f-e96d-4c8b-bd9c-a75316c9b4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfadcb9c-c146-42c0-9b5d-94b508d0abce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "C:\\Users\\mahmoud\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "import cv2\n",
    "import easyocr\n",
    "image = cv2.imread('Downloads/hgra.jpg')\n",
    "\n",
    "reader = easyocr.Reader(['en'])\n",
    "result = reader.readtext(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13fa4544-d7be-4c34-a469-d14639de79f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([[45, 114], [1012, 114], [1012, 287], [45, 287]],\n",
       "  'Ha] eV Jamal Kqxlrdon',\n",
       "  0.10258392271502134)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b513b9ae-6530-404d-b90d-5c32b6deb9e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TrOCRProcessor, VisionEncoderDecoderModel\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# Load model & processor\n",
    "processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-handwritten')\n",
    "model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-handwritten')\n",
    "\n",
    "# Load and process image\n",
    "image = Image.open('Downloads/hgra.jpg').convert(\"RGB\")\n",
    "pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values\n",
    "\n",
    "# Run inference\n",
    "generated_ids = model.generate(pixel_values)\n",
    "text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2760b6de-b091-425c-9429-8ba47f8e9c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8f0f983-1922-4d78-b0d8-323d907e5ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BubbleSheetProcessor:\n",
    "    def __init__(self,image_path):\n",
    "        self.image_path=image_path\n",
    "        self.nc=None\n",
    "        self.image=None\n",
    "        self.gray=None\n",
    "        self.warped=None\n",
    "        self.cropped=None\n",
    "        self.thresh=None\n",
    "        self.bubble_contours=None\n",
    "        self.answer_matrix=None\n",
    "    def load_image(self):\n",
    "        self.image = cv2.imread(self.image_path)\n",
    "        self.gray = cv2.cvtColor(self.image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    def warp_paper(self):\n",
    "        id_corner_map,self.nc=getIDCornerMap(self.gray)\n",
    "        self.warped=getWarpedImage(src_pts = getROI(id_corner_map),image=self.image)\n",
    "    def preprocess_cropped(self):\n",
    "        x, y, w, h = cv2.boundingRect(getLargestContour(self.warped))\n",
    "        self.cropped = self.warped[y+10:y+h-10, x+10:x+w-10]\n",
    "        \n",
    "        cropped_gray = cv2.cvtColor(self.cropped, cv2.COLOR_BGR2GRAY)\n",
    "        blurred = cv2.GaussianBlur(cropped_gray, (3, 3), 0)\n",
    "        #return binary image based on adaptive thresholding\n",
    "        self.thresh = cv2.adaptiveThreshold(blurred, 255, \n",
    "                                       cv2.ADAPTIVE_THRESH_MEAN_C, \n",
    "                                       cv2.THRESH_BINARY_INV, 49, 20)\n",
    "    \n",
    "    \n",
    "    def getFilledBubblesMatrix(self):\n",
    "        extracted_matrix=[]\n",
    "        for c in self.bubble_contours:\n",
    "            # Step 1: Create a black mask\n",
    "            mask = np.zeros(self.thresh.shape, dtype=\"uint8\")\n",
    "        \n",
    "            # Step 2: Draw the bubble contour filled with white on the mask\n",
    "            cv2.drawContours(mask, [c], -1, 255, -1)\n",
    "        \n",
    "            # Step 3: Apply the mask to binary_image image\n",
    "            masked_bubble = cv2.bitwise_and(self.thresh, self.thresh, mask=mask)\n",
    "        \n",
    "            # Step 4: Calculate number of white pixels\n",
    "            total = cv2.countNonZero(mask)\n",
    "            filled = cv2.countNonZero(masked_bubble)\n",
    "        \n",
    "            fill_ratio = filled / total\n",
    "            #print(fill_ratio)\n",
    "            if fill_ratio > 0.5:  # You can tweak 0.5 based on real data\n",
    "                extracted_matrix.append(1)\n",
    "            else:\n",
    "                extracted_matrix.append(0)\n",
    "        \n",
    "        self.answer_matrix= np.array(extracted_matrix).reshape(-1,self.nc)\n",
    "\n",
    "    def extract_bubble_contours(self):\n",
    "        self.bubble_contours=getBubbleContours(self.thresh,False)\n",
    "\n",
    "\n",
    "    def run_pipeline(self):\n",
    "        self.load_image()\n",
    "        self.warp_paper()\n",
    "        self.preprocess_cropped()\n",
    "        self.extract_bubble_contours()\n",
    "        self.getFilledBubblesMatrix()\n",
    "        return self.answer_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "123195b8-f73d-4b46-aaeb-c77ec0cdc76b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor=BubbleSheetProcessor('Downloads/modelanswer.jpg')\n",
    "processor.run_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fe4ba6c-c608-4606-b025-49af7c14c9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(model_answer_image, *students_answers_images):\n",
    "    processor=BubbleSheetProcessor(model_answer_image)\n",
    "    mam=processor.run_pipeline()\n",
    "    \n",
    "    for student_answer in students_answers_images:\n",
    "        processor=BubbleSheetProcessor(student_answer)\n",
    "        sam=processor.run_pipeline()\n",
    "        sam==mam\n",
    "        print(np.all(sam==mam,axis=1).sum())\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "275460ce-07c7-4a88-9ce7-6c9604a19b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "get_results('Downloads/modelanswer.jpg','Downloads/studentanswer.jpg','Downloads/student2answer.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202597d1-05e4-404e-ae6d-2ac6cd5c0616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8e279bfb-d708-49e2-a803-aeb66a945be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1=np.array([[1, 1, 0, 0, 0],\n",
    "       [1, 0, 0, 0, 0],\n",
    "       [1, 0, 0, 0, 0],\n",
    "       [0, 1, 0, 0, 0],\n",
    "       [0, 1, 0, 0, 0],\n",
    "       [0, 1, 0, 0, 0],\n",
    "       [0, 0, 1, 0, 0],\n",
    "       [0, 0, 1, 0, 0],\n",
    "       [0, 0, 1, 0, 0],\n",
    "       [0, 0, 0, 1, 0],\n",
    "       [0, 0, 0, 1, 0],\n",
    "       [0, 0, 0, 1, 0],\n",
    "       [0, 0, 0, 0, 1],\n",
    "       [0, 0, 0, 0, 1],\n",
    "       [0, 0, 0, 0, 1],\n",
    "       [0, 0, 0, 0, 1],\n",
    "       [0, 0, 0, 0, 1],\n",
    "       [0, 0, 0, 0, 1],\n",
    "       [0, 0, 0, 1, 0],\n",
    "       [0, 0, 0, 1, 0],\n",
    "       [0, 0, 0, 1, 0],\n",
    "       [0, 0, 1, 0, 0],\n",
    "       [0, 0, 0, 0, 0],\n",
    "       [0, 0, 1, 0, 0],\n",
    "       [0, 1, 0, 0, 0],\n",
    "       [0, 1, 0, 0, 0],\n",
    "       [0, 1, 0, 0, 0],\n",
    "       [1, 0, 0, 0, 0],\n",
    "       [1, 0, 0, 0, 0],\n",
    "       [1, 0, 0, 0, 0]])\n",
    "\n",
    "\n",
    "s2=np.array([[1, 1, 0, 0, 0],\n",
    "       [0, 1, 0, 0, 0],\n",
    "       [0,1, 0, 0, 0],\n",
    "       [0, 1, 0, 0, 0],\n",
    "       [0, 1, 0, 0, 0],\n",
    "       [0, 1, 0, 0, 0],\n",
    "       [0, 0, 1, 0, 0],\n",
    "       [0, 0, 1, 0, 0],\n",
    "       [0, 0, 1, 0, 0],\n",
    "       [0, 0, 0, 1, 0],\n",
    "       [0, 0, 0, 1, 0],\n",
    "       [0, 0, 0, 1, 0],\n",
    "       [0, 0, 0, 0, 1],\n",
    "       [0, 0, 0, 0, 1],\n",
    "       [0, 0, 0, 0, 1],\n",
    "       [0, 0, 0, 0, 1],\n",
    "       [0, 0, 0, 0, 1],\n",
    "       [0, 0, 0, 0, 1],\n",
    "       [0, 0, 0, 1, 0],\n",
    "       [0, 0, 0, 1, 0],\n",
    "       [0, 0, 0, 1, 0],\n",
    "       [0, 0, 1, 0, 0],\n",
    "       [0, 0, 0, 0, 0],\n",
    "       [0, 0, 1, 0, 0],\n",
    "       [0, 1, 0, 0, 0],\n",
    "       [0, 1, 0, 0, 0],\n",
    "       [0, 1, 0, 0, 0],\n",
    "       [1, 0, 0, 0, 0],\n",
    "       [1, 0, 0, 0, 0],\n",
    "       [1, 0, 0, 0, 0]])\n",
    "\n",
    "s3=np.array([[1, 0, 0, 0, 0],\n",
    "       [1, 0, 0, 0, 0],\n",
    "       [1, 0, 0, 0, 0],\n",
    "       [0, 1, 0, 0, 0],\n",
    "       [0, 1, 0, 0, 0],\n",
    "       [0, 1, 0, 0, 0],\n",
    "       [0, 0, 1, 0, 0],\n",
    "       [0, 0, 0, 1, 0],\n",
    "       [0, 0, 1, 0, 0],\n",
    "       [0, 0, 0, 1, 0],\n",
    "       [0, 0, 0, 1, 0],\n",
    "       [0, 0, 1, 0, 0],\n",
    "       [0, 0, 0, 0, 1],\n",
    "       [0, 0, 0, 0, 1],\n",
    "       [0, 0, 0, 0, 1],\n",
    "       [1, 0, 0, 0, 0],\n",
    "       [1, 0, 0, 0, 0],\n",
    "       [1, 0, 0, 0, 0],\n",
    "       [0, 1, 0, 0, 0],\n",
    "       [0, 1, 0, 0, 0],\n",
    "       [0, 0, 1, 0, 0],\n",
    "       [0, 0, 1, 0, 0],\n",
    "       [0, 0, 1, 0, 0],\n",
    "       [0, 0, 1, 0, 0],\n",
    "       [0, 0, 0, 1, 0],\n",
    "       [0, 0, 0, 1, 0],\n",
    "       [0, 0, 0, 1, 0],\n",
    "       [0, 0, 0, 0, 1],\n",
    "       [0, 0, 0, 0, 1],\n",
    "       [0, 0, 1, 0, 0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9ea84f89-9589-49a9-86f9-d0eefad37136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(s1^s2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "64a0ca76-a00f-4a0b-ae80-4f3f1a67d3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=np.array([[1, 0, 0, 0, 0],\n",
    "       [1, 0, 0, 0, 0],\n",
    "       [1, 0, 0, 0, 0],\n",
    "       [0, 1, 0, 0, 0],\n",
    "       [0, 1, 0, 0, 0],\n",
    "       [0, 1, 0, 0, 0],\n",
    "       [0, 0, 1, 0, 0],\n",
    "       [0, 0, 1, 0, 0],\n",
    "       [0, 0, 1, 0, 0],\n",
    "       [0, 0, 0, 1, 0],\n",
    "       [0, 0, 0, 1, 0],\n",
    "       [0, 0, 0, 1, 0],\n",
    "       [0, 0, 0, 0, 1],\n",
    "       [0, 0, 0, 0, 1],\n",
    "       [0, 0, 0, 0, 1],\n",
    "       [1, 0, 0, 0, 0],\n",
    "       [1, 0, 0, 0, 0],\n",
    "       [1, 0, 0, 0, 0],\n",
    "       [0, 1, 0, 0, 0],\n",
    "       [0, 1, 0, 0, 0],\n",
    "       [0, 1, 0, 0, 0],\n",
    "       [0, 0, 1, 0, 0],\n",
    "       [0, 0, 1, 0, 0],\n",
    "       [0, 0, 1, 0, 0],\n",
    "       [0, 0, 0, 1, 0],\n",
    "       [0, 0, 0, 1, 0],\n",
    "       [0, 0, 0, 1, 0],\n",
    "       [0, 0, 0, 0, 1],\n",
    "       [0, 0, 0, 0, 1],\n",
    "       [0, 0, 0, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29b107f-c2d9-497d-bf09-3880303a6d77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b195d5-7e47-4b7e-8d4d-7a2f1d303070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b736c9d4-4d8b-43b1-b4d3-d0d538f77bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
